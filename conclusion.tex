\chapter{Conclusion}

The objective of this thesis was to develop a new class of state estimators for legged robots able to fuse proprioceptive and exteroceptive
sensors. We advocated for the use of tightly-coupled formulations where all measurements and state variables are integrated into a single estimation 
problem. This type of estimator permits a greater accuracy and the estimation of extra parameters by leveraging all sensors correlations.
It also leverages a sound mathematical formulation to extend generic estimators to more diverse and numerous perception sources, toward whole-body estimation.
The accent was put on the necessary modularity of the formulations to make the mathematical developments extendable to new types of sensors. This 
was achieved through the use of Maximum-A-Posteriori estimation, modeled as Factor Graph optimization. All mathematical formulations used extensively the smooth manifold
and Lie group theories that best represent the geometry of the state variables. We also emphasize the generalizability of the developed measurement models. 
We recall here the technical contributions that be presented during this work.

\section{Contributions}

We developed a range of measurement models targeted at sensors present on legged platforms. These measurements models were integrated as factors in 
three factor-graph-based estimators.

\bigskip

We implemented a general factor for camera-based object-level pose estimations based on open source libraries. 

First, the \apriltag\ library was used 
to obtain poses of fiducial markers used to augment the scene with unique landmarks. We proposed a new analytical model to estimate the covariance of 
these measurements. We discussed the problem of the orientation ambiguity of these markers and proposed a practical method to alleviate this problem.
The anisotropic nature of the pose uncertainty was highlighted in simulated experiments. 

Second, we used a deep-learning-based framework to obtain the pose of known objects in the scene. A model based on empirical data was obtained through
experiments. We showed that we could fine-tune the model to elements of the scene of interest for legged-robots navigation such as stairs.

We proposed a leg-odometry model based on single foot matching.

One of the most important contributions of our work was the application of a generalized pre-integration theory to IMU and force-torque measurements. 

First, we proposed a new formulation of the IMU pre-integration algorithm based on a compact delta Lie group. This approach was compared
theoretically to the seminal work on IMU pre-integration. 

Second, we applied the same general pipeline to the pre-integration of
force-torque sensors present at the end-effectors of legged robots. This algorithm was shown to make possible the high-rate estimation of centroidal 
quantities and to observe a bias on the traditionally used kinematics-based computation of the CoM position.   

\bigskip

These measurements models were all integrated into the WOLF library \cite{sola2021wolf}, which provided the necessary modularity to formulate various estimation
problems. We applied these models to three applications.

\bigskip

First, we developed a visual-inertial SLAM system based on IMU pre-integration and the \apriltag\ pose measurement model. This estimator was validated through
a series of experiments conducted at LAAS on the \HRP{2} humanoid robot. We showed that the system provided both a localization with reasonable precision
for the locomotion of the robot on an experimental platform and a high rate, smooth estimation of the base velocity. Both were compared to a motion capture 
ground truth. 

Second, we proposed a tightly coupled algorithm for base and centroidal estimation. This estimator combined the pre-integration of IMU and force-torque data, 
leg odometry, and kinematics. We showed that the estimator enables to estimate the bias on CoM kinematics measurements, which is sometimes ignored
by controllers in first approximation. Experimental validation was conducted on simple trajectories performed on the Solo-12 quadruped robot. 

Finally, we implemented another object-level visual-inertial SLAM system based on an object pose estimation deep-learning framework. This system again used the 
IMU pre-integration as well as our measurement model based on an empirical model of the pose uncertainty. We showed that the trajectory of the system and objects
in the scene could be recovered and that the IMU contributed to the robustness of the system by alleviating the instability of the pose estimation. We proposed
as a proof of concept to perform VI-SLAM using stairs elements as landmarks. This dataset was recorded on the Solo-12 quadruped robot.


\section{Perspectives}
This work laid the foundations of a general factor-graph-based estimation framework for legged robotics. However, a lot of alleys have yet to be explored 
to obtain a usable estimator on any legged platform. Here we present a few of the next projects that we wish to undertake.

\subsection{Short term}
We developed on one hand an object-level visual-inertial system and on the other hand a proprioceptive estimator for the sense of balance. A short-term goal
would be to merge both estimators in one, providing simultaneously a high-rate estimation for control and a non-drifting localization based on SLAM. 

We began to work in this direction by recording datasets using Solo-12 as an experimental platform. For this experiment, we will concentrate on estimating the 
base state by including inertial, kinematics, and \apriltag\ measurements in the estimator. 

We also plan to integrate the system in a feedback loop with the current controller of Solo-12. For the moment, instabilities in the solver convergence times prevented
us from obtaining a real-time estimate for the proprioceptive estimator, while the \apriltag\ based SLAM system works in real-time. One of the solutions would 
be a hyperspace search on the numerous options provided by the Ceres solver \cite{ceres-solver}. Another is to search for the most appropriate size of the graph,
that is the frequency of \keyframe\ creation. Marginalization of older states and sparsification procedures should also be investigated.



\subsection{Mid term}

In a second time, we would like to further strengthen the environmental perception of our system. This would be done by developing or integrating a vision system
based on general geometric constraints. Many of the most mature vision-based SLAM systems are based on sparse feature extraction. This will be 
the first venue that we explore. 

Our ideal realization would then be an integrated demo on Solo-12 with an odometry estimator based on kinematics, IMU, and a sparse feature KLT tracking-based 
vision front-end. This system would then easily be extended with either of our object-level SLAM algorithms to provide loop closures and, therefore, a global localization.



\subsection{Longer term}

We will here develop a few ideas and reflections that our work on a general estimator for legged robots brought.

Following the endeavour to develop an estimator fusing as many sources of information, we could turn our attention to a 
\textit{whole-body} state estimation. As we have seen, the standard proprioception sensor set for legged robots is an IMU attached to the robot base
and encoders at the joints (possibly along with joint torque, motor current, and force sensors at the end effector). This set of sensor
is enough to implement a proprioceptive odometry of the base but is quite limited when it comes to perceiving finer information about the state of the robot
and its environment. In particular, the kinesthesis sense of artificial legged systems is far from the subtleties of their biological counterparts, in particular
because of the rigid segment assumptions. One solution is to augment the robot with other sensors measuring these flexibilities. Recent solutions have demonstrated
the applicability of such methods by using placing IMUs in each segment of an exoskeleton. One might also imagine adding strain gauges to measure directly 
the deflections of certain beams.  The sense of touch is for the moment also underrepresented in legged robotics. Some teams propose to add sheets
of strain cells are an artificial skin to 

- WB estimation
- Detection de contact
- Object SLAM
- Facteur appris 
- SLAM dense
- Optim WOLF

